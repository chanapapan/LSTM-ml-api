{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f9b3e5d-8618-4312-a2f2-e4f7469d3a4b",
   "metadata": {},
   "source": [
    "# LSTM for WiseSight dataset\n",
    "\n",
    "Create a deep sentiment analysis model using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8c48c3-ec18-4db7-808f-71d0caf3320c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d264460-04ba-4ae1-8b3d-ea78a379bb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import copy\n",
    "import pickle\n",
    "from IPython import display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pythainlp.ulmfit import *\n",
    "from pythainlp.ulmfit import process_thai\n",
    "import string, re\n",
    "import random\n",
    "import emoji\n",
    "import io\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch import nn\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "\n",
    "def get_freer_gpu():\n",
    "    os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >gpu_free')\n",
    "    memory_available = [int(x.split()[2]) for x in open('gpu_free', 'r').readlines()]\n",
    "    gpu = f'cuda:{np.argmax(memory_available)}'\n",
    "    if os.path.exists(\"gpu_free\"):\n",
    "        os.remove(\"gpu_free\")\n",
    "    else:\n",
    "          print(\"The file does not exist\") \n",
    "    return gpu\n",
    "\n",
    "device = get_freer_gpu()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e16e5f-23e4-41a6-8a92-a1a3ea7ee983",
   "metadata": {},
   "source": [
    "## Load config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad715c46-a318-428b-be3e-67b1d096668c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-3cb79654d1db>:4: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(ymlfile)\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"config.yml\", \"r\") as ymlfile:\n",
    "    config = yaml.load(ymlfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d3237b-8e62-431c-8e9d-c2ae67224c45",
   "metadata": {},
   "source": [
    "## Load All text to create vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4838b674-c77f-4a16-bef3-c05268a31dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26737"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = config['data_folder']\n",
    "\n",
    "all_text = []\n",
    "\n",
    "# get all data from both train and test set for creating vocabulary\n",
    "with open(data_folder + \"train.txt\") as f:\n",
    "    for line in f:\n",
    "        all_text.append(line.strip())\n",
    "with open(data_folder + \"test.txt\") as f:\n",
    "    for line in f:\n",
    "        all_text.append(line.strip())\n",
    "\n",
    "len(all_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfa6c57-cd2c-45fc-b887-12cf4613f9f3",
   "metadata": {},
   "source": [
    "## Text Cleaning & Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0a102a1-b630-4b91-b67c-45c28e8c2d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/PyThaiNLP/wisesight-sentiment/blob/master/kaggle-competition/competition.ipynb\n",
    "EMOJI = re.compile(\"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    u\"\\U000024C2-\\U0001F251\"\n",
    "    u\"\\U0001f926-\\U0001f937\"\n",
    "    u\"\\U00010000-\\U0010ffff\"\n",
    "    u\"\\u2640-\\u2642\" \n",
    "    u\"\\u2600-\\u2B55\"\n",
    "    u\"\\u200d\"\n",
    "    u\"\\u23cf\"\n",
    "    u\"\\u23e9\"\n",
    "    u\"\\u231a\"\n",
    "    u\"\\ufe0f\"  # dingbats\n",
    "    u\"\\u3030\"\n",
    "                  \"]+\", re.UNICODE)\n",
    "\n",
    "def replace_url(text):\n",
    "    URL_PATTERN = r\"\"\"(?i)\\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\\s()<>{}\\[\\]]+|\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’])|(?:(?<!@)[a-z0-9]+(?:[.\\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\\b/?(?!@)))\"\"\"\n",
    "    return re.sub(URL_PATTERN, 'xxurl', text)\n",
    "\n",
    "def replace_rep(text):\n",
    "    def _replace_rep(m):\n",
    "        c,cc = m.groups()\n",
    "        return f'{c}xxrep'\n",
    "    re_rep = re.compile(r'(\\S)(\\1{2,})')\n",
    "    return re_rep.sub(_replace_rep, text)\n",
    "\n",
    "def process_text(text):\n",
    "    #pre rules\n",
    "    res = text.lower().strip()\n",
    "    res = replace_url(res)\n",
    "    res = replace_rep(res)\n",
    "    \n",
    "    PUNC  = string.punctuation\n",
    "    res = ''.join([c for c in text if c not in PUNC])\n",
    "    \n",
    "    HASHTAG_PATTERN = r\"#[a-zA-Z0-9ก-๙]+\"\n",
    "    res = re.sub(HASHTAG_PATTERN, \"\", res)\n",
    "    \n",
    "    MENTION_PATTERN = r\"@[a-zA-Z0-9ก-๙]+\"\n",
    "    res = re.sub(MENTION_PATTERN, \"\", res)\n",
    "    \n",
    "    res = re.sub(EMOJI, \"\", res)\n",
    "    \n",
    "    res = [word for word in process_thai(res) if word and not re.search(pattern=r\"\\s+\", string=word)]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76cfcb87-efca-4e83-8705-f33f36e83675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ประเทศ', 'เรา', 'ผลิต', 'และ', 'ส่งออก', 'ยาสูบ', 'เยอะ', 'สุด', 'ใน', 'โลก', 'จิง', 'ป่าว', 'คับ'], ['คะ'], ['อิ', 'เหี้ย', 'ออม', 'ทำ', 'กู', 'อยาก', 'กิน', 'เอ็ม', 'เค'], [], ['สวัสดี', 'วัน', 'พุธ', 'แนน', 'อะไร', 'นะ']]\n"
     ]
    }
   ],
   "source": [
    "# convert each sample into a list of tokens\n",
    "all_text = [process_text(text) for text in all_text]\n",
    "print(all_text[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4834f2f0-52ba-47cf-a2c4-71f2f7ae01e1",
   "metadata": {},
   "source": [
    "## Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "471a8b28-68d1-41a2-a676-4fb573d111d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tokens into integers          \n",
    "vocab = build_vocab_from_iterator(all_text, specials=[\"<unk>\", \"<pad>\" ])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7c4c962-5f66-4e71-b027-524c5cda9d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 848, 33]\n",
      "27165\n"
     ]
    }
   ],
   "source": [
    "print(vocab(['กิน', 'ข้าว', 'กัน']))\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4775ad6-df05-49b2-936a-6b1efec09200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vocab\n",
    "# with open(config['vocab_path'], 'wb') as f:\n",
    "#     pickle.dump(vocab, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Load vocab\n",
    "# with open(config['vocab_path'], 'rb') as f:\n",
    "#     vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c64c076-d87e-4438-8972-6841ce2ba33f",
   "metadata": {},
   "source": [
    "## Preparing data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11271e6a-2037-472d-9b96-a20dcc0ef100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24063\n",
      "24063\n",
      "2674\n",
      "2674\n"
     ]
    }
   ],
   "source": [
    "def txt_to_list(txt_path):\n",
    "    data_list = []\n",
    "    with open(txt_path) as f:\n",
    "        for line in f:\n",
    "            data_list.append(line.strip())\n",
    "    print(len(data_list))\n",
    "    return data_list\n",
    "\n",
    "train_text  = txt_to_list(data_folder + \"train.txt\")\n",
    "train_label = txt_to_list(data_folder + \"train_label.txt\")\n",
    "\n",
    "test_text  = txt_to_list(data_folder + \"test.txt\")\n",
    "test_label = txt_to_list(data_folder + \"test_label.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eff2f8-5f1d-4966-b832-6cc8d7a688b0",
   "metadata": {},
   "source": [
    "## Convert string labels into int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5bc9661-b9f3-4013-8e2c-d065d0338f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neu', 'neu', 'neg', 'neu', 'neu', 'neu', 'neg', 'neu', 'neg', 'neu']\n",
      "[0, 0, 2, 0, 0, 0, 2, 0, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "LABEL_TO_INT = {'neu':0, 'pos':1, 'neg':2, 'q':3}\n",
    "INT_TO_LABEL = {v:k for k,v in LABEL_TO_INT.items()}\n",
    "\n",
    "print(train_label[:10])\n",
    "\n",
    "train_label = [LABEL_TO_INT[label] for label in train_label]\n",
    "test_label  = [LABEL_TO_INT[label] for label in test_label]\n",
    "\n",
    "print(train_label[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e18b12-73c8-411b-97d7-8b4b259b72b8",
   "metadata": {},
   "source": [
    "## Split the training data into Train and Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e27dc4cc-12df-44de-a92f-4b810e569fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20453\n",
      "20453\n",
      "3610\n",
      "3610\n",
      "2674\n",
      "2674\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_text, train_label, test_size=0.15, random_state=42, stratify = train_label)\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_val))\n",
    "print(len(y_val))\n",
    "\n",
    "X_test, y_test = test_text, test_label\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be86ed6-8ed4-4c20-94b6-82361cfad94a",
   "metadata": {},
   "source": [
    "## Use RandomOverSampler to help dealing with Imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6726732a-d082-4e78-928c-f4006b9e6717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44556\n",
      "44556\n"
     ]
    }
   ],
   "source": [
    "df_x_train = pd.DataFrame(X_train)\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "\n",
    "# do oversampling just for the training set\n",
    "df_x_train, y_train = ros.fit_resample(df_x_train, y_train)\n",
    "\n",
    "X_train = df_x_train.loc[:, 0].tolist()\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0edc14-fbd0-4ca3-9123-6cb10dcf05f9",
   "metadata": {},
   "source": [
    "## Create custom Pytorch dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07742cb3-6366-4f88-8d06-92163a260662",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, text_list, label_list, vocab):\n",
    "        self.text_list  = text_list\n",
    "        self.label_list = label_list\n",
    "        self.vocab      = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_list)\n",
    "    \n",
    "    # preprocess and tokenize the text then use vocab to convert tokens into integers\n",
    "    def __getitem__(self, idx):\n",
    "        text = (self.vocab(process_text(self.text_list[idx])))\n",
    "        if len(text) == 0 :\n",
    "            text = vocab(['<unk>'])\n",
    "        return (text, self.label_list[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f4eec9-4d84-4047-b060-6be08cd2ab71",
   "metadata": {},
   "source": [
    "## Creat Train, Validation and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "435e7aae-549c-4c88-bd9c-f283cade37ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(X_train, y_train, vocab)\n",
    "val_dataset   = MyDataset(X_val,  y_val, vocab)\n",
    "test_dataset  = MyDataset(X_test, y_test, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0388ce6f-5116-4da3-89f7-19e1c93b0e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 254, 3927, 2, 23388, 3744, 10467, 258, 19, 175, 186, 176, 17, 279, 162, 19, 2820, 73, 718, 22, 254, 52, 379, 924, 12, 29, 54, 447, 684, 143, 6470, 104, 37, 133, 49, 97, 42, 1074, 25993, 12, 1087, 3927, 844, 1756, 74, 22956, 157, 6, 22, 4, 463, 47, 7, 5, 99, 87, 85, 133, 5379, 12, 451, 26, 16]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# the sequence length of the samples are not equal\n",
    "for text, label in train_dataset:\n",
    "    print(text)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3773d2c-1021-4820-a1ff-0b8da42bca2a",
   "metadata": {},
   "source": [
    "## Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a651413-956f-4d58-8eed-804f73468de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for nn.embedding\n",
    "PAD_IDX       = vocab['<pad>'] # tell nn.embedding to ignore padding\n",
    "\n",
    "# Training hyperparameters\n",
    "batch_size    = config['batch_size']\n",
    "num_epochs    = config['num_epochs']\n",
    "lr            = config['lr'] # empirically set\n",
    "\n",
    "num_workers   = config['num_workers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5993e2c7-23c6-4a72-a562-3cdf90c14a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad so that all sequence in the same batch has the same length with pad_sequence\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, length_list = [], [], []\n",
    "    for (_text, _label) in batch:\n",
    "        text_tensor = torch.tensor(_text, dtype=torch.int64)\n",
    "        \n",
    "        text_list.append(text_tensor)\n",
    "        label_list.append(_label)\n",
    "        length_list.append(text_tensor.size(0))  #++<-----packed padded sequences require length\n",
    "    \n",
    "    return torch.tensor(label_list, dtype=torch.float64), pad_sequence(text_list, padding_value=PAD_IDX, batch_first=True), torch.tensor(length_list, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82983ca-091c-476a-9e7f-6705afdf26a7",
   "metadata": {},
   "source": [
    "## Creat Train, Validation and Test Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05a77020-502d-439f-b1cb-3ec19b82c50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/archive/gpu/home/users/jakrapop.a/.conda/envs/jakrapop_nlu/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                              shuffle=True, collate_fn=collate_batch, num_workers = num_workers)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size,\n",
    "                              shuffle=True, collate_fn=collate_batch, num_workers = num_workers)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                              shuffle=True, collate_fn=collate_batch, num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7e9dad0-deb0-495d-8cc2-d40d42e1d77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 1., 1., 0., 1., 2., 3., 3., 3., 0., 2., 3., 1., 2., 1., 0., 2.,\n",
      "        0., 1., 2., 3., 1., 0., 0., 1., 0., 3., 1., 0., 3., 1., 3., 0., 1., 0.,\n",
      "        0., 3., 3., 1., 0., 3., 1., 2., 1., 1., 3., 1., 0., 1., 0., 3., 0., 3.,\n",
      "        0., 0., 1., 2., 2., 2., 2., 1., 0., 2., 3., 0., 2., 0., 2., 1., 0., 1.,\n",
      "        2., 1., 3., 2., 0., 0., 1., 1., 0., 3., 2., 0., 1., 2., 3., 3., 1., 2.,\n",
      "        0., 3., 1., 0., 2., 3., 0., 3., 3., 2., 1., 0., 2., 3., 3., 2., 2., 1.,\n",
      "        1., 2., 3., 3., 0., 0., 3., 0., 2., 2., 3., 2., 0., 1., 0., 3., 0., 0.,\n",
      "        2., 3.], dtype=torch.float64)\n",
      "tensor([[   5,  150, 2006,  ...,    1,    1,    1],\n",
      "        [ 587,   12,    1,  ...,    1,    1,    1],\n",
      "        [ 165,    2, 1561,  ...,    1,    1,    1],\n",
      "        ...,\n",
      "        [ 423,  310, 5198,  ...,    1,    1,    1],\n",
      "        [  66,   84,  120,  ...,    1,    1,    1],\n",
      "        [  59, 6219,    6,  ...,    1,    1,    1]])\n",
      "tensor([  4,   2,  50,   3,  43,   8,  26,   9,  16,   9,  34,  37,  12,   7,\n",
      "         10,  17,   3,  14,  13,   2,  10,   3,  53,   7,   8,   9,   8,   8,\n",
      "          5,  12,  20,   2,   8,   9,  11,   8,  87,  18,  21,  10,  10,   4,\n",
      "          3,   7,   3,  11,   3,   3,  26,  28,  55,  22,  23,   4,  70,  10,\n",
      "         10,  26,  12,   9,  14,   7,  39,  53,  11,   4,  12,   3,   3,   6,\n",
      "        119,   5,   2,   5,  50,  15,   3,  11,  80,   2,  46,   7,   8,   7,\n",
      "          3,  38,  11,  17,   3,  66,   4,  13,   4,   4,  29,  17,   6,   8,\n",
      "         50,   6,  61,  51,  69,  24,   4,   1,   5,  31,   6,   4,  19,  30,\n",
      "          3,   3,   3, 101,  32,  20,  20,  13,   5,  25,   5,  12,   6,  10,\n",
      "         10,   5])\n"
     ]
    }
   ],
   "source": [
    "for label, text, text_length in train_loader:\n",
    "    print(label)\n",
    "    print(text)\n",
    "    print(text_length)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73707b99-35b7-488f-bd2d-2f6813636b0e",
   "metadata": {},
   "source": [
    "## Define MySentimentModel class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3f3248a-6ec4-4987-95da-431013d1710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySentimentModel(nn.Module):\n",
    "    def __init__(self, config, vocab, INT_TO_LABEL):\n",
    "        super().__init__()\n",
    "        self.vocab = vocab\n",
    "        input_dim = len(self.vocab)\n",
    "        PAD_IDX   = self.vocab['<pad>']\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, config['embed_dim'], padding_idx=PAD_IDX)\n",
    "        self.lstm = nn.LSTM(input_size   = config['embed_dim'], \n",
    "                           hidden_size   = config['hidden_dim'], \n",
    "                           num_layers    = config['num_layers'], \n",
    "                           bidirectional = config['bidirectional'], \n",
    "                           dropout       = config['dropout'],\n",
    "                           batch_first   = True)\n",
    "        self.fc = nn.Linear(config['hidden_dim'] * 2, config['output_dim'])\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        # text = (batch_size, seq len)\n",
    "        embedded = self.embedding(text) # (batch_size, seq_len, embed_dim)\n",
    "        \n",
    "        # pack the padded sequences\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'), enforce_sorted=False, batch_first=True)\n",
    "\n",
    "        packed_output, (hn, cn) = self.lstm(packed_embedded)\n",
    "        \n",
    "        # concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        hn = torch.cat((hn[-2,:,:], hn[-1,:,:]), dim = 1)\n",
    "        \n",
    "        return self.fc(hn)\n",
    "    \n",
    "    def predict(self, text:str) -> str:\n",
    "        text             = self.vocab(process_text(text))\n",
    "        text             = torch.tensor(text).reshape(1,-1)\n",
    "        text             = self.embedding(text)\n",
    "        output, (hn, cn) = self.lstm(text)\n",
    "        hn               = torch.cat((hn[-2,:,:], hn[-1,:,:]), dim = 1)\n",
    "        output           = self.fc(hn)\n",
    "        \n",
    "        pred_class = torch.argmax(torch.softmax(output, dim=1), dim=1).detach().flatten().cpu().tolist()\n",
    "        pred_class = [INT_TO_LABEL[pred] for pred in pred_class][0]\n",
    "        \n",
    "        return pred_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1633ef-834d-444a-bd02-37db685669be",
   "metadata": {},
   "source": [
    "## Define model, optimizer and criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d756efa-636c-4af2-b5c6-b6ee1d9db6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MySentimentModel(config, vocab, INT_TO_LABEL).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10796d93-3d07-45df-ba34-81b3433ffda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929e9d1f-8899-4fdc-828e-4e9e4ecbd5e5",
   "metadata": {},
   "source": [
    "## Define training and evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70029164-72e7-4c1f-92fb-dddb811342a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, model, train_loader, val_loader, test_loader, optimizer, criterion, device):\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        train_loss    = _train(model, train_loader, optimizer, criterion, device)\n",
    "        valid_loss, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "        \n",
    "        print(f\"EPOCH : {epoch} | Train Loss : {train_loss} | Val Loss : {valid_loss}\")\n",
    "        \n",
    "        # for plotting\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        \n",
    "        # copy save model with the lowest validation loss\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_epoch = epoch\n",
    "\n",
    "    # get test accuracy from best model\n",
    "    test_loss, y_test_pred, y_true = evaluate(best_model, test_loader, criterion, device)\n",
    "    print(f\"FINAL Best Model from Best Epoch {best_epoch} Test Loss = {test_loss}\")\n",
    "    print(classification_report(y_true, y_test_pred, target_names=['neu', 'pos', 'neg', 'q']))\n",
    "    \n",
    "    # save best model\n",
    "    torch.save(best_model.state_dict(), \"best_LSTM_weights.pth\")\n",
    "    \n",
    "    return train_losses, valid_losses, test_loss, best_epoch, best_model, y_true, y_test_pred\n",
    "\n",
    "def _train(model, train_loader,  optimizer, criterion, device):\n",
    "\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "\n",
    "    for i, (label, text, text_length) in enumerate(train_loader):\n",
    "        \n",
    "        label       = label.to(device).long()\n",
    "        text        = text.to(device) \n",
    "        text_length = text_length.to(device)\n",
    "\n",
    "        output = model(text, text_length)\n",
    "        loss   = criterion(output, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss += loss.item()\n",
    "        \n",
    "    epoch_train_loss = epoch_train_loss / len(train_loader)\n",
    "    \n",
    "    return epoch_train_loss\n",
    "\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (label, text, text_length) in enumerate(val_loader):\n",
    "            \n",
    "            label       = label.to(device).long()   \n",
    "            text        = text.to(device) \n",
    "            text_length = text_length.to(device)\n",
    "            \n",
    "            output = model(text, text_length)\n",
    "            loss   = criterion(output, label)\n",
    "            \n",
    "            pred_class = torch.argmax(torch.softmax(output, dim=1), dim=1).detach().flatten().cpu().tolist()\n",
    "            all_predictions.extend(pred_class)\n",
    "            all_true_labels.extend(label.cpu().tolist())\n",
    "            \n",
    "            epoch_val_loss += loss.item()\n",
    "    \n",
    "    epoch_val_loss =  epoch_val_loss / len(val_loader)\n",
    "    \n",
    "    return epoch_val_loss, all_predictions, all_true_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6781c8b-f84e-4c86-933a-e49c499368a9",
   "metadata": {},
   "source": [
    "## Train and Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a7423cd-44c0-4b15-9755-3c513f0c9e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 0 | Train Loss : 1.309769074349827 | Val Loss : 1.3371446625939731\n",
      "EPOCH : 1 | Train Loss : 1.022073834536752 | Val Loss : 1.1778017981299038\n",
      "EPOCH : 2 | Train Loss : 0.8605189946797652 | Val Loss : 1.0869369136876073\n",
      "EPOCH : 3 | Train Loss : 0.7611880553486012 | Val Loss : 1.0381380504575268\n",
      "EPOCH : 4 | Train Loss : 0.7009485789219766 | Val Loss : 1.000857803328284\n",
      "EPOCH : 5 | Train Loss : 0.6609716357337712 | Val Loss : 0.9950277497028482\n",
      "EPOCH : 6 | Train Loss : 0.6292546655352956 | Val Loss : 0.9737184664298748\n",
      "EPOCH : 7 | Train Loss : 0.6003023339035176 | Val Loss : 0.9626492899039696\n",
      "EPOCH : 8 | Train Loss : 0.5740119179545295 | Val Loss : 0.9927346048683956\n",
      "EPOCH : 9 | Train Loss : 0.5526069814291247 | Val Loss : 0.958082299807976\n",
      "EPOCH : 10 | Train Loss : 0.5298931276729933 | Val Loss : 0.9713896759625139\n",
      "EPOCH : 11 | Train Loss : 0.5112586097423532 | Val Loss : 1.013009406369308\n",
      "EPOCH : 12 | Train Loss : 0.49070214021171743 | Val Loss : 0.9877110246954293\n",
      "EPOCH : 13 | Train Loss : 0.4717142186567913 | Val Loss : 0.9806938705773189\n",
      "EPOCH : 14 | Train Loss : 0.45735607319711613 | Val Loss : 0.9830662649253319\n",
      "EPOCH : 15 | Train Loss : 0.4398087922344918 | Val Loss : 1.0002414645819828\n",
      "EPOCH : 16 | Train Loss : 0.4208718416171634 | Val Loss : 1.024566923749858\n",
      "EPOCH : 17 | Train Loss : 0.4074316601186222 | Val Loss : 1.0241691696232762\n",
      "EPOCH : 18 | Train Loss : 0.39102630885077755 | Val Loss : 1.042074071949926\n",
      "EPOCH : 19 | Train Loss : 0.3763852577581788 | Val Loss : 1.0420600936330597\n",
      "EPOCH : 20 | Train Loss : 0.36503536179448265 | Val Loss : 1.0603554577663028\n",
      "EPOCH : 21 | Train Loss : 0.35502713666775165 | Val Loss : 1.067605133714347\n",
      "EPOCH : 22 | Train Loss : 0.3384669824025692 | Val Loss : 1.0916788598586773\n",
      "EPOCH : 23 | Train Loss : 0.32796198642014773 | Val Loss : 1.107923302157172\n",
      "EPOCH : 24 | Train Loss : 0.3201472912101144 | Val Loss : 1.1372670140759698\n",
      "EPOCH : 25 | Train Loss : 0.30987507297008976 | Val Loss : 1.1960293424540553\n",
      "EPOCH : 26 | Train Loss : 0.2970754632294007 | Val Loss : 1.2076356698726785\n",
      "EPOCH : 27 | Train Loss : 0.2893600550114596 | Val Loss : 1.1946569126227806\n",
      "EPOCH : 28 | Train Loss : 0.27786714282623337 | Val Loss : 1.2298690409495914\n",
      "EPOCH : 29 | Train Loss : 0.2694995510885572 | Val Loss : 1.2278078218986248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/archive/gpu/home/users/jakrapop.a/.conda/envs/jakrapop_nlu/lib/python3.9/site-packages/torch/nn/modules/rnn.py:772: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "  result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL Best Model from Best Epoch 9 Test Loss = 0.9454598001071385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neu       0.76      0.57      0.65      1456\n",
      "         pos       0.42      0.58      0.48       478\n",
      "         neg       0.64      0.78      0.70       683\n",
      "           q       0.27      0.46      0.34        57\n",
      "\n",
      "    accuracy                           0.62      2674\n",
      "   macro avg       0.52      0.59      0.54      2674\n",
      "weighted avg       0.66      0.62      0.63      2674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, valid_losses, test_loss, best_epoch, best_model, y_true, y_test_pred = train(num_epochs,\n",
    "                                                                     model,\n",
    "                                                                     train_loader,\n",
    "                                                                     val_loader,\n",
    "                                                                     test_loader,\n",
    "                                                                     optimizer,\n",
    "                                                                     criterion,\n",
    "                                                                     device,\n",
    "                                                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13832573-2195-4422-a81b-6943a4a15693",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8dc49502-499b-4e51-a450-9751715a564c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(y_true , y_test_pred)\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "            xticklabels=['neu', 'pos', 'neg', 'q'], yticklabels=['neu', 'pos', 'neg', 'q'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true,
  "vscode": {
   "interpreter": {
    "hash": "5289b8c979b58076e9bd7e65db45d7d4db5bfe1f67ec508cedcc00d9a8d063a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
